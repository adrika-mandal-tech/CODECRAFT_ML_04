# ğŸ¤Ÿ American Sign Language (ASL) Detector using Hand Gestures

This project is a real-time **American Sign Language (ASL) alphabet detector** that recognizes **all 26 letters (Aâ€“Z)** using hand gestures captured via webcam.

It combines the power of **Computer Vision** and **Deep Learning** to interpret gestures based on ASL rules â€” making communication more inclusive and accessible.

---

## ğŸ§  What It Does

ğŸ“¸ **Captures hand gestures** in real-time using your webcam  
ğŸ§¾ **Classifies them** into one of the 26 English alphabets (Aâ€“Z)  
ğŸ–ï¸ Follows standard **American Sign Language** rules  
ğŸ“Š Uses a **trained ML model** for accurate alphabet prediction

---

## ğŸ§ª Tech Stack

| Tool/Library | Purpose |
|--------------|---------|
| ğŸ” OpenCV     | Capturing and processing real-time video feed |
| ğŸ¤– TensorFlow | Building and loading the trained ML model |
| ğŸ–ï¸ MediaPipe  | Real-time hand tracking and landmark detection |

---



## ğŸ—‚ï¸ Project Structure

```
ASL_Detector/
â”‚
â”œâ”€â”€ Model/                # Trained .tflite or .h5 model
â”‚
â”œâ”€â”€ dataset/              # Folder containing training images (Aâ€“Z)
â”‚
â”œâ”€â”€ screenshots/          # Visuals and sample output images
â”‚
â”œâ”€â”€ asl_detector.py       # Main Python script for running real-time ASL detection
â”‚
â”œâ”€â”€ requirements.txt      # List of Python dependencies
â”‚
â””â”€â”€ README.md             # Project documentation
```
